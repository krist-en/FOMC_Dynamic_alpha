{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import yfinance as yf\n","import pandas as pd\n","\n","# Step 1: Scrape the current S&P 500 component tickers from Wikipedia, retreived on 2024.06.30\n","url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n","sp500_table = pd.read_html(url, header=0)[0]\n","sp500_components = sp500_table['Symbol'].tolist()\n","\n","# Define the date range\n","start_date = '2011-02-01'\n","end_date = '2020-09-30'\n","\n","# Initialize empty DataFrames to hold the historical data\n","historical_returns = pd.DataFrame()\n","historical_volume = pd.DataFrame()\n","historical_close = pd.DataFrame()\n","\n","# Step 2: Fetch the historical data for each ticker\n","for ticker in sp500_components:\n","    stock = yf.Ticker(ticker)\n","    hist = stock.history(start=start_date, end=end_date)\n","\n","    # Reshape data for close panel (Date - Close)\n","    close_panel = hist[['Close']].rename(columns={'Close': ticker})\n","    historical_close = pd.concat([historical_close, close_panel], axis=1)\n","\n","    # Reshape data for returns panel (Date - Ret)\n","    hist['Ret'] = hist['Close'].pct_change() * 100  # Calculate return in percent\n","    ret_panel = hist[['Ret']].rename(columns={'Ret': ticker})\n","    historical_returns = pd.concat([historical_returns, ret_panel], axis=1)\n","\n","    # Reshape data for volume panel (Date - Volume)\n","    volume_panel = hist[['Volume']].rename(columns={'Volume': ticker})\n","    historical_volume = pd.concat([historical_volume, volume_panel], axis=1)\n","\n","# Reset the index of both DataFrames\n","historical_close.reset_index(inplace=True)\n","historical_close['Date'] = pd.to_datetime(historical_close['Date']).dt.strftime('%Y-%m-%d')\n","historical_returns.reset_index(inplace=True)\n","historical_returns['Date'] = pd.to_datetime(historical_returns['Date']).dt.strftime('%Y-%m-%d')\n","historical_volume.reset_index(inplace=True)\n","historical_volume['Date'] = pd.to_datetime(historical_volume['Date']).dt.strftime('%Y-%m-%d')\n","\n","# Display the first few rows of the returns panel\n","print(\"Returns Panel:\")\n","print(historical_returns.head())\n","\n","# Display the first few rows of the volume panel\n","print(\"\\nVolume Panel:\")\n","print(historical_volume.head())\n"],"metadata":{"id":"xjPbyIe5mBFX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719776662489,"user_tz":240,"elapsed":142745,"user":{"displayName":"zhihao wang","userId":"04684194927419039210"}},"outputId":"eb716823-a84e-4fe2-9a43-17df5e55508a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:yfinance:ABNB: Data doesn't exist for startDate = 1296536400, endDate = 1601438400\n","ERROR:yfinance:$BRK.B: possibly delisted; No timezone found\n","ERROR:yfinance:$BF.B: possibly delisted; No price data found  (1d 2011-02-01 -> 2020-09-30)\n"]},{"output_type":"stream","name":"stdout","text":["$BF.B: possibly delisted; No price data found  (1d 2011-02-01 -> 2020-09-30)\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:yfinance:CEG: Data doesn't exist for startDate = 1296536400, endDate = 1601438400\n","ERROR:yfinance:GEHC: Data doesn't exist for startDate = 1296536400, endDate = 1601438400\n","ERROR:yfinance:GEV: Data doesn't exist for startDate = 1296536400, endDate = 1601438400\n","ERROR:yfinance:KVUE: Data doesn't exist for startDate = 1296536400, endDate = 1601438400\n","ERROR:yfinance:SOLV: Data doesn't exist for startDate = 1296536400, endDate = 1601438400\n","ERROR:yfinance:VLTO: Data doesn't exist for startDate = 1296536400, endDate = 1601438400\n","<ipython-input-9-0d33ee8b762a>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  historical_close.reset_index(inplace=True)\n","<ipython-input-9-0d33ee8b762a>:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  historical_returns.reset_index(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["Returns Panel:\n","         Date       MMM       AOS       ABT  ABBV       ACN      ADBE  \\\n","0  2011-02-01       NaN       NaN       NaN   NaN       NaN       NaN   \n","1  2011-02-02 -0.045565 -0.623311  1.105376   NaN  0.362776 -0.238729   \n","2  2011-02-03  0.227903 -0.673593  0.590500   NaN  0.418600  0.299128   \n","3  2011-02-04  0.386582  0.093548  0.260803   NaN -0.435774 -0.507003   \n","4  2011-02-07  0.566328  0.070068 -0.932313   NaN  0.228342  0.599523   \n","\n","        AMD       AES       AFL  ...        WY       WMB       WTW      WYNN  \\\n","0       NaN       NaN       NaN  ...       NaN       NaN       NaN       NaN   \n","1  0.851578 -0.789886 -2.443201  ... -1.339524 -0.840320 -1.438485 -0.260147   \n","2  0.482509  0.000000 -0.420334  ...  0.042409  1.694908  0.351319  0.445901   \n","3  0.840332 -1.114667  1.072822  ...  3.053463 -0.507265  0.996558 -1.122297   \n","4 -0.833330  1.046727  2.140278  ... -2.839475  0.437011  0.053330 -0.042325   \n","\n","        XEL  XYL       YUM      ZBRA       ZBH  ZTS  \n","0       NaN  NaN       NaN       NaN       NaN  NaN  \n","1 -0.628112  NaN  0.653686 -0.500002  0.514873  NaN  \n","2 -0.252844  NaN  3.142734  0.703524 -0.033073  NaN  \n","3 -0.084512  NaN  0.142167  0.673644  0.247988  NaN  \n","4  0.845637  NaN  0.202842  0.247837 -1.088236  NaN  \n","\n","[5 rows x 504 columns]\n","\n","Volume Panel:\n","         Date      MMM      AOS       ABT  ABBV      ACN     ADBE       AMD  \\\n","0  2011-02-01  4778259  1574000  27734473   NaN  3427000  4738000  40250200   \n","1  2011-02-02  3459550  1235200  26265527   NaN  2378800  3046100  36239600   \n","2  2011-02-03  2370711   932400  17199250   NaN  2514500  3043800  22946500   \n","3  2011-02-04  2360784   808400  20698416   NaN  1757700  6534800  21103900   \n","4  2011-02-07  3135553  1196800  23649854   NaN  2193800  3679400  18586100   \n","\n","       AES       AFL  ...        WY      WMB     WTW     WYNN      XEL  XYL  \\\n","0  7967900   8944400  ...   8399100  8053852  476065  2245500  1468800  NaN   \n","1  3680300  12097200  ...   6473000  3934249  467760  1414500  1584000  NaN   \n","2  5999000   8063400  ...   6880800  9872915  332728  2402600  1912500  NaN   \n","3  3997700   5372400  ...  10446800  6060353  653377  2198900  2089500  NaN   \n","4  2638400   8980000  ...  13807000  5238224  308304  2038400  1141800  NaN   \n","\n","        YUM    ZBRA      ZBH  ZTS  \n","0   4485001  239200  1726795  NaN  \n","1   5346726   98700  2064223  NaN  \n","2  11473385  104700  2347679  NaN  \n","3   5038202   99100  2518968  NaN  \n","4   5310143  131300  2850834  NaN  \n","\n","[5 rows x 504 columns]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-0d33ee8b762a>:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  historical_volume.reset_index(inplace=True)\n"]}]},{"cell_type":"code","source":["# Save the DataFrame to a CSV file\n","historical_close.to_csv('sp500_P_daily.csv', index=False)\n","historical_returns.to_csv('sp500_R_daily.csv', index=False)\n","historical_volume.to_csv('sp500_V_daily.csv', index=False)"],"metadata":{"id":"yxTyBK5RrrXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AHBVbdZ1rx4O"},"execution_count":null,"outputs":[]}]}